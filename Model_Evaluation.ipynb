{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtM6Zov4VU0vxZBCleTKng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharatbajoria/Summer-Internship/blob/master/Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUI0fhCXTONF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def statistical_signficance(statistics,stats,stdev,topic_df_T,alpha,null_hyp,model1,np,pd):\n",
        "  #topics_df_T: Dataframe of words for any model\n",
        "  #col: Mtx with Topic Header, col[i]= Topic-i\n",
        "  #alpha: Critical p-Value for rejecting null hypothesis\n",
        "  #null_hyp: Value of mean for Null Hypothesis\n",
        "  col=[]\n",
        "  a='Topic- '\n",
        "  for i in range(len(topic_df_T.columns)):\n",
        "    col.append(a+str(i+1))\n",
        "\n",
        "  \n",
        "  Average_comparison=null_hyp\n",
        "  ds=[]\n",
        "  for i in range((len(col))) :\n",
        "    ds.append(list(topic_df_T[col[i]]))\n",
        "\n",
        "  ds# ds[i] is i-th list of Topic-i\n",
        "\n",
        "  simscore_topic=[]#initiating mtx for sim scores/cosine scores\n",
        "\n",
        "\n",
        "  for p in range(len(ds)):\n",
        "    k=len(ds[p])\n",
        "    o=0\n",
        "\n",
        "    sim=[]\n",
        "    simt=[]\n",
        "  \n",
        "    for i in range(k):\n",
        "      simt=[]\n",
        "      for j in range(k)  :\n",
        "        o=model1.similarity(ds[p][i],ds[p][j])\n",
        "        simt.append(o)\n",
        "\n",
        "      sim.append(simt)\n",
        "\n",
        "    simscore_topic.append(sim)\n",
        "# 3-D list, simscore_topic[i] is similarity scores for topic-i\n",
        "# simscore_topic[i][j] is list of similarity score of j-th word in i-th Topic with other words\n",
        "\n",
        "\n",
        "  \n",
        "  t_score_all=[]\n",
        "  p_value_all=[]\n",
        "  mean=0\n",
        "  sd=0\n",
        "\n",
        "  t_value=0\n",
        "  dup_score=[]\n",
        "  p=0\n",
        "  p_value=[]\n",
        "  t2=0\n",
        "  for i in range(len(ds)):\n",
        "    \n",
        "    t=[]\n",
        "    p_value_topic=[]\n",
        "    for j in range(len(ds[i])):         \n",
        "      dup_score=simscore_topic[i][j][:]    \n",
        "      dup_score.pop(j)# removing score of i-th element with itself which is=1\n",
        "      t2,p=stats.ttest_1samp(np.array(dup_score),popmean=np.array(Average_comparison))\n",
        "      \n",
        "      t.append(t2)\n",
        "      p_value_topic.append(p)\n",
        "      pass\n",
        "\n",
        "    t_score_all.append(t)\n",
        "    p_value_all.append(p_value_topic)\n",
        "  \n",
        "  t=0\n",
        "  word_to_remove=[] #initializing tuple to save topicid and word outside cluster\n",
        "  for i in range(len(p_value_all)):\n",
        "    word=[]\n",
        "    for j in range(len(p_value_all[i])):\n",
        "      if (p_value_all[i][j]>= alpha) or(t_score_all[i][j]<0):\n",
        "        word.append(ds[i][j])\n",
        "    \n",
        "    if len(word)>0:\n",
        "      t+=len(word)#counting number of words to be removed\n",
        "    \n",
        "    word_to_remove.append(word)\n",
        "\n",
        "\n",
        "# word_to_remove[i] list of words to remove from topic-i\n",
        "#ds[i] list of words in topic-i\n",
        "#t number of words to be removed in a algorithm\n",
        "# simscore_topic[i][j] is list of similarity score of j-th word in i-th Topic with other words\n",
        "\n",
        "  \n",
        "  return word_to_remove,ds,t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkMXL_OWmvxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_model(number_words_removed_lsi, number_words_removed_hdp, number_words_removed_lda,lda,lsi,hdp):\n",
        "  \n",
        "  Best_model=[number_words_removed_lsi, number_words_removed_hdp, number_words_removed_lda]\n",
        "  k=min(Best_model)\n",
        "  if k==number_words_removed_lsi:    \n",
        "    ideal_model=lsi\n",
        "  if k==number_words_removed_hdp:    \n",
        "    ideal_model=hdp\n",
        "  if k==number_words_removed_lda:    \n",
        "    ideal_model=lda\n",
        "  \n",
        "  \n",
        "  return ideal_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do5tWhRspZnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_topic(ideal_model,dictionary,new_token):\n",
        "  lda1=ideal_model\n",
        "  tk=[]\n",
        "  for i in new_token:\n",
        "    tk.extend(i)\n",
        "\n",
        "  new_topic=lda1[dictionary.doc2bow(tk)]\n",
        "  New_Topic_id,New_Topic_Prob= [],[]\n",
        "  a='Topic '\n",
        "  for i in new_topic:    \n",
        "    a='Topic:'+ str(i[0]+1)    \n",
        "    New_Topic_id.append(a)\n",
        "    New_Topic_Prob.append((i[1]*100))\n",
        "\n",
        "  return New_Topic_id,New_Topic_Prob"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}